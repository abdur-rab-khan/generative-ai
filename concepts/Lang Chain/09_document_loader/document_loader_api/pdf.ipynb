{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce93fec7",
   "metadata": {},
   "source": [
    "- Table of content\n",
    "  - [Loading a PDF's](#loading-a-pdfs)\n",
    "    - [Simple and fast text extraction](#simple-and-fast-text-extraction)\n",
    "      - [Vector search over PDF's](#vector-search-over-pdfs)\n",
    "    - [Layout analysis and extraction of text from images](#layout-analysis-and-extraction-of-text-from-images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c6ee68",
   "metadata": {},
   "source": [
    "# Loading a PDF's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeff9e9",
   "metadata": {},
   "source": [
    "- PDF's are typically represent via text boxes. that may also contain images.\n",
    "- A PDF Parser are combination of following:\n",
    "  1.  Convert text box in to lines, paragraphs, and other structure using heuristics or ML inference.\n",
    "  2. Run OCR (an electronic device that scan handwritten, printed text into encoded text) on the image to detect text.\n",
    "  3. Classify text as belonging paragraph, lists, tables other structure.\n",
    "  4. Structure text into table rows and columns, or key-value pairs.\n",
    "\n",
    "- **IMPORTANT TO NOTE**\n",
    "  - My modern LLM's supports multi-model data such as images.\n",
    "  - So we can you following approach instead of parsing PDF.\n",
    "    - We can pass the image of pdf page.\n",
    "    - Below we have example how to do tht.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f711c2",
   "metadata": {},
   "source": [
    "## Simple and fast text extraction.\n",
    "\n",
    "- It is very simple, If you want to extract the text content embedded in a PDF. \n",
    "- It only extract the text from the pdf, it will not parse text inside the image.\n",
    "- It return a list of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects per -- one per page. Containing page text in the Document's **`page_content`** attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da0244f",
   "metadata": {},
   "source": [
    "- LangChain [document loaders](../document_loader.md) implements with `lazy_load`, for async variants `alazy_load`, which returns an iterators of Document objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e45c9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"same_files/welcome.pdf\")\n",
    "\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2f87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 MetaData\n",
      "{'producer': 'Adobe PDF Library 21.1.174', 'creator': 'Acrobat PDFMaker 21 for Word', 'creationdate': '2024-06-18T22:34:29+00:00', 'author': 'Adobe', 'comments': '', 'company': 'Adobe', 'keywords': '', 'moddate': '2024-06-24T08:31:18-07:00', 'sourcemodified': 'D:20240618223427', 'subject': '', 'title': 'Welcome to Adobe Acrobat', 'source': 'same_files/welcome.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}\n",
      "Page 1 Content\n",
      "Welcome to  \n",
      "Adobe Acrobat \n",
      "Here are five tips to get real work  \n",
      "done from anywhere with Acrobat.  \n",
      "01 Work where you want \n",
      "02 Meet Acrobat AI Assistant \n",
      "03 Present perfect content \n",
      "04 Share files with others \n",
      "05 Get help from Adobe\n"
     ]
    }
   ],
   "source": [
    "print(f\"Page 1 MetaData\")\n",
    "print(f\"{pages[0].metadata}\")  # It also store the corresponding page numbers.\n",
    "print(\"Page 1 Content\")\n",
    "print(f\"{pages[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62ad7f8",
   "metadata": {},
   "source": [
    "### Vector search over PDF's\n",
    "\n",
    "- Once we have loaded pdf's into LangChain [Document](../document_loader.md) object. we can index them (e.g a RAG application) in the usual way.\n",
    "- Below we use OpenAI embedding, although any LangChain embedding model will sufficient for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8cbf1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 4: 04 Share files with others \n",
      "Send and manage \n",
      " \n",
      "Now you can share files for \n",
      "viewing, commenting, or \n",
      "signature—and track their \n",
      "status every step of the way. \n",
      "Share files fast. Click, type, and \n",
      "send. It’s that easy. \n",
      "Collaborate better. Subscribers \n",
      "can also send files for e-signature or for review to collect \n",
      "group feedback in a single shared file. \n",
      "Manage your files. You’re in control. Track your file, \n",
      "forward it to others, or stop sharing it at any time.\n",
      "\n",
      "Page 3: 03 Present perfect content \n",
      "Combine and organize files \n",
      " \n",
      "Share materials exactly how you want—quickly and \n",
      "easily. \n",
      "Merge multiple files into \n",
      "one PDF. Combine different \n",
      "file types—spreadsheets, \n",
      "images, web pages, and \n",
      "videos—into a single PDF \n",
      "file that’s easy to share or \n",
      "archive. You can even add \n",
      "an entire folder. \n",
      "Organize pages. Rotate, \n",
      "delete, reorder, or insert pages in your PDF on your \n",
      "desktop, tablet, or mobile device.\n",
      "\n",
      "Page 5: 05 Get help from Adobe \n",
      "We’ve got your back \n",
      "Take advantage of tutorials \n",
      "and forums—and share your \n",
      "feedback with the Acrobat \n",
      "team. \n",
      "Get tutorials. Become an expert \n",
      "with short videos and online \n",
      "instruction. \n",
      "Visit Adobe Community. Ask questions and find answers \n",
      "in Acrobat forums. \n",
      "Share your feedback. We need your help to continue to \n",
      "make Acrobat the best solution available. Ple\n",
      "ase share your \n",
      "thoughts.\n",
      "\n",
      "Page 0: Welcome to  \n",
      "Adobe Acrobat \n",
      "Here are five tips to get real work  \n",
      "done from anywhere with Acrobat.  \n",
      "01 Work where you want \n",
      "02 Meet Acrobat AI Assistant \n",
      "03 Present perfect content \n",
      "04 Share files with others \n",
      "05 Get help from Adobe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vector_store = InMemoryVectorStore.from_documents(\n",
    "    pages, OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "docs = vector_store.similarity_search(\"tell me about share files with others\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad429a",
   "metadata": {},
   "source": [
    "### Layout analysis and extraction of text from images\n",
    "\n",
    "- If you want more control over the text extraction such as (extracting text from image, titles, tables other structure).\n",
    "- The following methods are good for these requires.\n",
    "- It will returns a list of document objects each object will represent a structure on the page.\n",
    "- The document meta data store page numbers and other information related to the objects.\n",
    "- It use **`langchain_structured`** library. see from [here](https://python.langchain.com/docs/integrations/document_loaders/unstructured_file/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b2057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "if \"UNSTRUCTURED_API_KEY\" not in os.environ:\n",
    "    os.environ[\"UNSTRUCTURED_API_KEY\"] = getpass.getpass(\n",
    "        \"Unstructured API Key:\")\n",
    "\n",
    "\n",
    "loader = UnstructuredLoader(\n",
    "    file_path=\"sample_files/welcome.pdf\",\n",
    "    strategy=\"hi_res\",\n",
    "    partition_via_api=True,\n",
    "    coordinates=True,\n",
    ")\n",
    "docs = []\n",
    "for doc in loader.lazy_load():\n",
    "    docs.append(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
