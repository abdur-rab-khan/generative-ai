{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51103f62",
   "metadata": {},
   "source": [
    "- [Vector Store](#vector-store)\n",
    "  - [Basic Implementation via `InMemoryVectorStore`](#basic-implementation-via-inmemoryvectorstore)\n",
    "    - [Add Documents](#add-documents)\n",
    "    - [Delete Documents](#delete)\n",
    "    - [Search Over Documents](#search)\n",
    "      - [Similarity Metrics](#similarity-metrics)\n",
    "      - [Similarity Search](#similarity-search)\n",
    "    - [Metadata filtering](#metadata-filtering)\n",
    "  - [Advanced Search and Retrieval Techniques](#advanced-search-and-retrieval-techniques)\n",
    "  - [PineCone](#pinecone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74969b72",
   "metadata": {},
   "source": [
    "# Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9b44a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "pdf_path = \"../sample_files/progit.pdf\"\n",
    "\n",
    "if not path.exists(pdf_path):\n",
    "    raise Exception(\"Invalid path, File does not exits\")\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ade83",
   "metadata": {},
   "source": [
    "## Basic Implementation via `InMemoryVectorStore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b701f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# Initializing with an embedded model\n",
    "vector_store = InMemoryVectorStore(embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560c433",
   "metadata": {},
   "source": [
    "- Extracting Documents from pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5bc286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "raw_docs = []\n",
    "\n",
    "# Initializing PDF loader\n",
    "pdf_loader = PyPDFLoader(pdf_path)\n",
    "async for doc in pdf_loader.alazy_load():\n",
    "    current_page = doc.metadata[\"page_label\"]\n",
    "\n",
    "    if not current_page.isdigit():\n",
    "        continue\n",
    "\n",
    "    current_page_num = int(current_page)\n",
    "    if current_page_num > 8:\n",
    "        if current_page_num >= 492:\n",
    "            break\n",
    "\n",
    "        raw_docs.append(doc)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "documents = text_splitter.split_documents(raw_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a930a0",
   "metadata": {},
   "source": [
    "### Add Documents\n",
    "\n",
    "- The **`add_documents`** method works with list of **`Document`** objects all have `page_content` and `meta_data` attribute. making them universal way to store unstructured text and associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0eefce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed940928",
   "metadata": {},
   "source": [
    "- We have to provide **`ID's`** for the documents, so that instead of adding the same document multiple times, we can update the existing document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d45147",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents=documents, ids=[\"doc1\", \"doc2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46381f6",
   "metadata": {},
   "source": [
    "### Delete "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e99cd",
   "metadata": {},
   "source": [
    "- To delete documents, use the delete method which takes a list of document IDs to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1062ba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete(ids=[\"doc1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a91f79d",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e80766",
   "metadata": {},
   "source": [
    "- Vector store embed and store the documents that added. If we pass query it convert into vector and perform a similarity search over the embedded documents.\n",
    "- There are two important concept for searching\n",
    "  1. Needs a way to measure that similarity between query and any embedded documents. \n",
    "  2. Needs are algorithm to efficiently perform the similarity search across all embedded documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b05a146",
   "metadata": {},
   "source": [
    "#### Similarity metrics\n",
    "\n",
    "- The important thing about embeddings are they can be comparable using simple **Mathematical operations:**\n",
    "  1. **Cosine Similarity:**  A metric used to measure how similar two vectors are, based on the angle between them, regardless of their magnitude.\n",
    "  2. **Euclidean Distance:** Euclidean distance is a measure of the **straight-line** distance between two points in a **multi-dimensional space**\n",
    "  3. **Dot Product:** An operation in linear algebra that takes two vectors and returns a single scalar value. It reflects how much two vectors point in the same direction.\n",
    "\n",
    "- The choice of similarity metrics can something selected during initialization of vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3d199",
   "metadata": {},
   "source": [
    "#### Similarity Search\n",
    "\n",
    "- Given similarity metrics measure the distance between the embedded query and any embedded documents.\n",
    "- There are various algorithms for efficiently search over all embedded documents, Many vector stores implement **`HNSW (Hierarchical Navigable Small World)`**, a graph based index structure that allows for similarity search. \n",
    "- In LangChain, under the hood use this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad07b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"my query\"\n",
    "docs = vectorstore.similarity_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4154c5f2",
   "metadata": {},
   "source": [
    "- Many vectorstores support search parameters to be passed with **`similarity_search`** method.\n",
    "- [**PineCone**](#pinecone) supports several parameters. Many vectorstores support the k, which controls the number of Documents to return, and filter, which allows for filtering documents by metadata.\n",
    "\n",
    "- query (str) – Text to look up documents similar to.\n",
    "- k (int) – Number of Documents to return. Defaults to 4.\n",
    "- filter (dict | None) – Dictionary of argument(s) to filter on metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196395f",
   "metadata": {},
   "source": [
    "### Metadata filtering\n",
    "\n",
    "- **Vector Stores** implement a search algorithm to efficiently search over all embedded documents to find most relevant one. many vector stores also supports **Metadata filtering**.\n",
    "- These two concepts work well together\n",
    "    1. **Semantic Search:**  Query the unstructured data directly, often via embedding or keyword similarity.\n",
    "    2. **Metadata Search:** Apply structured query to the metadata, filtering specific documents.\n",
    "\n",
    "    ```py\n",
    "    # Example of PineCone\n",
    "    \n",
    "    vector_store.similarity_search(\n",
    "        \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "        k=2, # Number of documents return\n",
    "        filter={\"source\": \"tweet\"},\n",
    "    )\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d22761d",
   "metadata": {},
   "source": [
    "### [Advanced search and retrieval techniques](https://python.langchain.com/docs/concepts/vectorstores/#advanced-search-and-retrieval-techniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a1fa4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## PineCone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a18d01c",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6188a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ, getenv\n",
    "from getpass import getpass\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "if not getenv(\"PINECONE_API_KEY\"):\n",
    "    environ[\"PINECONE_API_KEY\"] = getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "\n",
    "pine_cone_api_key = environ[\"PINECONE_API_KEY\"]\n",
    "\n",
    "pc = Pinecone(api_key=pine_cone_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59779f19",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "- Before initialization, let's connect to PineCone **index**. If that named **index** not exist, than will create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89283df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = \"embeddings-test-index\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6ffe5e",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80066642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afe65ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7feeb7",
   "metadata": {},
   "source": [
    "\n",
    "### Manage vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ce4b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add some documents\n",
    "\n",
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da7685d",
   "metadata": {},
   "source": [
    "### Add items to vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84969c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f1488b54-6e54-420c-9290-ad4221dcce28',\n",
       " '7c402871-55e1-4747-9001-ee0a48093439',\n",
       " 'bb963abb-4564-479c-a2eb-7ceaeb7a1dcc',\n",
       " '41c0b0ac-339f-425f-acaf-6acbae15efd9',\n",
       " 'f6f60f8e-063e-4713-9676-e915c6a28f13',\n",
       " 'a8484eac-9709-41c3-8976-a81641c9e7c7',\n",
       " '75321538-01b9-4389-9c77-ea102198817a',\n",
       " '0260f310-4950-4ec6-a23d-0e103d981799',\n",
       " '399c3cf1-8529-484f-b2ca-b67f7a2dadbd',\n",
       " 'e51887e3-abe8-43fc-863e-d898dfaeff02']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b0bf6",
   "metadata": {},
   "source": [
    "### Delete items from vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bf56fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete(ids=[doc_ids[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b2f99e",
   "metadata": {},
   "source": [
    "## Query Directly\n",
    "\n",
    "- Let's search simple similarity search over vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae32ded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
      "--> LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n",
      "--> Wow! That was an amazing movie. I can't wait to see it again. [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "result = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=3,  # Number of documents to return, 4 default\n",
    "    filter={\"source\": \"tweet\"},  # Add filtration with the help of metadata\n",
    ")\n",
    "\n",
    "for res in result:\n",
    "    print(f\"--> {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aa1f12",
   "metadata": {},
   "source": [
    "- We can also search with score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3984556d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.569310] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"}\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff65172",
   "metadata": {},
   "source": [
    "### Query by turning into retriever\n",
    "\n",
    "- You can also transform the vector store into a retriever for easier usage in your chains.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b617d6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='41c0b0ac-339f-425f-acaf-6acbae15efd9', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 1, \"score_threshold\": 0.4},\n",
    ")\n",
    "retriever.invoke(\"Stealing from the bank is a crime\",\n",
    "                 filter={\"source\": \"news\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
