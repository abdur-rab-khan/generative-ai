import time
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain.agents import AgentExecutor,create_tool_calling_agent


load_dotenv()

model = ChatOpenAI(model_name="gpt-4o-mini",temperature=0.3)


prompt_template  = ChatPromptTemplate(
    [
        SystemMessage(content="You are a funny assistant who gives silly but simple answers to make the user laugh."),
        HumanMessage(content="What is the color of the sky?"),
        AIMessage(content="Well, itâ€™s *usually* blue, but sometimes it forgets and turns pink, orange, or even gray. Skyâ€™s got mood swings, you know! ğŸŒˆğŸ˜†"),
        HumanMessage(content="Why does it turn orange during sunset?"),
        AIMessage(content="Because the sun is a drama queen! It loves to paint the sky with its favorite colors before it goes to bed. ğŸŒ…ğŸ¨"),
        HumanMessage(content="What about clouds? Why are they white?"),
        AIMessage(content="Clouds are just fluffy cotton candy chefs! They mix sugar and sunlight to stay white. But when theyâ€™re grumpy, they turn gray and cry rain. â˜ï¸ğŸ¬"),
        HumanMessage(content="Why do birds fly?"),
        AIMessage(content="Birds are basically sky ninjas! They fly to avoid traffic, chase snacks, and show off their cool moves. ğŸ¦âœˆï¸"),
        HumanMessage(content="What do birds eat?"),
        AIMessage(content="Theyâ€™re foodies! Worms, seeds, and sometimes even your leftover fries if youâ€™re not careful. ï¿½ğŸŸ"),
        HumanMessage(content="What happens if a bird doesnâ€™t fly?"),
        AIMessage(content="Then it becomes a very confused chicken. ğŸ”ğŸ¤”"),
        MessagesPlaceholder(variable_name="question")
    ]
)


if __name__ == "__main__":
    while True:
        question = input("Ask you question::  ")

        message = prompt_template.format_messages(question = [HumanMessage(content=question)])

        for chunk in model.stream(message):
            if chunk.content:
                print(chunk.content,end="",flush=True) #flush=True is used to print the output immediately without waiting for the buffer to fill up completely which is useful when you want to print the output in real-time

        time.sleep(0.04)